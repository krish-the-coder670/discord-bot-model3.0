import csv
import os
import re
import json
from datetime import datetime, timedelta
import asyncio
import threading
import time
from collections import deque, defaultdict
import pickle
import hashlib

# Import with error handling
try:
    import discord
    DISCORD_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Discord.py not available: {e}")
    DISCORD_AVAILABLE = False
    discord = None

try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Pandas/NumPy not available: {e}")
    PANDAS_AVAILABLE = False
    pd = None
    np = None

try:
    from mlx_lm import load, generate
    import mlx.core as mx
    MLX_AVAILABLE = True
except ImportError as e:
    print(f"Warning: MLX not available: {e}")
    MLX_AVAILABLE = False
    load = None
    generate = None
    mx = None

try:
    from sentence_transformers import SentenceTransformer
    import faiss
    EMBEDDINGS_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Sentence transformers/FAISS not available: {e}")
    EMBEDDINGS_AVAILABLE = False
    SentenceTransformer = None
    faiss = None

try:
    import emoji
    import markdown
    from bs4 import BeautifulSoup
    import psutil
    TEXT_PROCESSING_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Text processing libraries not available: {e}")
    TEXT_PROCESSING_AVAILABLE = False
    emoji = None
    markdown = None
    BeautifulSoup = None
    psutil = None

# Discord.py-self setup for real account
if DISCORD_AVAILABLE:
    intents = discord.Intents.default()
    intents.messages = True
    intents.message_content = True
    bot = discord.Client(intents=intents)
else:
    bot = None
    print("Discord bot not available - Discord.py import failed")

# Configuration files
CONFIG_FILE = "bot_config.json"
SETUP_FILE = "setup_config.json"

def load_config():
    """Load bot configuration from web UI"""
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    return {}

def load_setup_config():
    """Load setup configuration"""
    if os.path.exists(SETUP_FILE):
        with open(SETUP_FILE, 'r') as f:
            return json.load(f)
    return {
        "discord_token": "",
        "huggingface_token": "",
        "csv_file_path": "Downloads/GC data.csv",
        "setup_complete": False
    }

# Advanced Memory Management
MESSAGE_CACHE = deque(maxlen=2000)  # Increased cache size for better recall
USER_PERSONALITIES = defaultdict(dict)
CONVERSATION_MEMORY = defaultdict(list)  # Comprehensive conversation tracking
USER_INTERACTION_HISTORY = defaultdict(lambda: {'last_seen': None, 'message_count': 0, 'topics': [], 'preferred_name': None, 'interactions': []})
RESPONSE_CACHE = {}
DEBUG_CHANNEL = None  # Assign this to a specific channel ID after initialization
MEMORY_THRESHOLD = 75  # Adjusted threshold for responsiveness
LAST_MEMORY_WARNING = None

def initialize_files():
    """Initialize CSV file if it doesn't exist"""
    setup_config = load_setup_config()
    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
    
    # Create directory if it doesn't exist
    os.makedirs(os.path.dirname(csv_file), exist_ok=True)
    
    if not os.path.exists(csv_file):
        with open(csv_file, 'w') as f:
            f.write("Date,Username,User tag,Content,Mentions,link\n")

def clean_markdown(text):
    """Remove Discord markdown formatting"""
    # Remove bold, italic, underline, strikethrough
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # Bold
    text = re.sub(r'\*(.*?)\*', r'\1', text)      # Italic
    text = re.sub(r'__(.*?)__', r'\1', text)      # Underline
    text = re.sub(r'~~(.*?)~~', r'\1', text)      # Strikethrough
    text = re.sub(r'`(.*?)`', r'\1', text)        # Code
    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)  # Code blocks
    text = re.sub(r'<@!?(\d+)>', '', text)        # User mentions
    text = re.sub(r'<#(\d+)>', '', text)          # Channel mentions
    text = re.sub(r'<@&(\d+)>', '', text)         # Role mentions
    text = re.sub(r'https?://\S+', '', text)      # URLs
    return text.strip()

def extract_emojis(text):
    """Extract emojis and convert to descriptions"""
    if TEXT_PROCESSING_AVAILABLE and emoji:
        return emoji.demojize(text, delimiters=("[", "]"))
    return text

def update_csv(message):
    """Update CSV with new message, cleaning markdown and handling emojis"""
    setup_config = load_setup_config()
    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
    
    cleaned_content = clean_markdown(message.content)
    emoji_content = extract_emojis(cleaned_content)
    
    with open(csv_file, 'a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow([
            message.created_at.strftime("%Y-%m-%d,%H:%M:%S"),
            message.author.name,
            str(message.author.id),
            emoji_content,
            ",".join([str(m.id) for m in message.mentions]),
            message.attachments[0].url if message.attachments else ""
        ])

def update_user_preference(message):
    """Detect user's preferred way to be addressed and update interaction history"""
    user_id = message.author.id
    # Example logic to determine preferred name
    if 'call me' in message.content.lower():
        words = message.content.split()
        if 'call' in words:
            index = words.index('call')
            if index + 2 < len(words) and words[index + 1] == 'me':
                preferred_name = words[index + 2].strip().strip('.,!')
                USER_INTERACTION_HISTORY[user_id]['preferred_name'] = preferred_name
                return preferred_name
    return None

def analyze_user_personality(username):
    """Analyze user's communication patterns from CSV data"""
    setup_config = load_setup_config()
    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
    
    if not os.path.exists(csv_file) or not PANDAS_AVAILABLE:
        return "neutral"
    
    df = pd.read_csv(csv_file)
    user_messages = df[df['Username'] == username]['Content'].tolist()
    
    if not user_messages:
        return "neutral"
    
    # Analyze common patterns
    personality = {
        'uses_emojis': any('[' in msg and ']' in msg for msg in user_messages),
        'uses_caps': any(msg.isupper() for msg in user_messages),
        'uses_abbreviations': any(len(msg.split()) < 3 for msg in user_messages),
        'uses_slang': any(word in ' '.join(user_messages).lower() for word in ['bruh', 'fr', 'ngl', 'smh', 'jk']),
        'message_length': sum(len(msg) for msg in user_messages) / len(user_messages) if user_messages else 0,
        'common_words': []
    }
    
    # Get most common words
    all_words = ' '.join(user_messages).lower().split()
    word_counts = {}
    for word in all_words:
        if len(word) > 2:
            word_counts[word] = word_counts.get(word, 0) + 1
    
    personality['common_words'] = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    
    return personality

def generate_user_style_response(username, base_response):
    """Generate response reflecting user's communication style"""
    personality = analyze_user_personality(username)
    
    if personality == "neutral":
        return base_response

    # Tailor response based on traits
    if personality.get('uses_emojis', False):
        import random
        emojis = ['üôÇ', 'üòÑ', 'üòÇ']
        base_response += " " + random.choice(emojis)

    if personality.get('uses_slang', False):
        slang_mappings = {"I think": "ngl", "I believe": "fr", "really": "rly", "you know": "y'know"}
        for key, val in slang_mappings.items():
            base_response = base_response.replace(key, val)

    if personality.get('uses_caps', False):
        base_response = base_response.upper()

    import random
    base_response += " " + "!" * random.randint(1, 2)  # Add excitement

    return base_response

# Semantic search setup
if EMBEDDINGS_AVAILABLE:
    try:
        embedder = SentenceTransformer('all-MiniLM-L6-v2')
        index = faiss.IndexFlatIP(384)  # Match MiniLM dimension
        print("‚úÖ Embeddings system initialized")
    except Exception as e:
        print(f"Warning: Failed to initialize embeddings: {e}")
        embedder = None
        index = None
        EMBEDDINGS_AVAILABLE = False
else:
    embedder = None
    index = None

def build_index():
    """Build FAISS index from CSV data"""
    if not EMBEDDINGS_AVAILABLE or not PANDAS_AVAILABLE:
        print("Skipping index build - required libraries not available")
        return
        
    setup_config = load_setup_config()
    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
    
    if not os.path.exists(csv_file):
        print(f"CSV file not found: {csv_file}")
        return
    
    try:
        df = pd.read_csv(csv_file)
        if len(df) == 0:
            print("CSV file is empty")
            return
        
        embeddings = embedder.encode(df['Content'].tolist())
        faiss.normalize_L2(embeddings)
        index.add(embeddings)
        
        # Save index
        index_file = "embeddings.index"
        faiss.write_index(index, index_file)
        print(f"‚úÖ Built index with {len(df)} messages")
    except Exception as e:
        print(f"Error building index: {e}")

# MLX model setup
model, tokenizer = None, None
MODEL_STATUS = {'loading': False, 'loaded': False, 'error': None}
SYSTEM_MONITOR = {'cpu': 0.0, 'memory': 0.0, 'uptime': 0.0}  # More detailed monitoring

async def send_debug_message(channel, message):
    """Send debug message in code format"""
    if channel:
        await channel.send(f"`{message}`")

async def monitor_system_resources():
    """Monitor system resources and send warnings"""
    global LAST_MEMORY_WARNING, SYSTEM_MONITOR
    
    if not TEXT_PROCESSING_AVAILABLE or not psutil:
        print("System monitoring disabled - psutil not available")
        return
    
    while True:
        try:
            # Get system stats
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            SYSTEM_MONITOR['cpu'] = cpu_percent
            SYSTEM_MONITOR['memory'] = memory_percent
            
            # Check memory threshold
            if memory_percent > MEMORY_THRESHOLD:
                current_time = datetime.now()
                if not LAST_MEMORY_WARNING or (current_time - LAST_MEMORY_WARNING) > timedelta(minutes=5):
                    if DEBUG_CHANNEL:
                        await send_debug_message(DEBUG_CHANNEL, 
                            f"Warning: Low memory, responses will be delayed! (Memory: {memory_percent:.1f}%)")
                    LAST_MEMORY_WARNING = current_time
            
            await asyncio.sleep(30)  # Check every 30 seconds
        except Exception as e:
            print(f"System monitor error: {e}")
            await asyncio.sleep(60)

def save_conversation_memory():
    """Save conversation memory to disk"""
    memory_file = "conversation_memory.pkl"
    try:
        with open(memory_file, 'wb') as f:
            pickle.dump({
                'conversations': dict(CONVERSATION_MEMORY),
                'user_history': dict(USER_INTERACTION_HISTORY),
                'personalities': USER_PERSONALITIES,
                'response_cache': RESPONSE_CACHE
            }, f)
    except Exception as e:
        print(f"Error saving memory: {e}")

def load_conversation_memory():
    """Load conversation memory from disk"""
    memory_file = "conversation_memory.pkl"
    if os.path.exists(memory_file):
        try:
            with open(memory_file, 'rb') as f:
                data = pickle.load(f)
                CONVERSATION_MEMORY.update(data.get('conversations', {}))
                USER_INTERACTION_HISTORY.update(data.get('user_history', {}))
                USER_PERSONALITIES.update(data.get('personalities', {}))
                RESPONSE_CACHE.update(data.get('response_cache', {}))
                print("Loaded conversation memory successfully")
        except Exception as e:
            print(f"Error loading memory: {e}")

def get_response_cache_key(prompt, context):
    """Generate cache key for responses"""
    combined = f"{prompt}:{context}"
    return hashlib.md5(combined.encode()).hexdigest()

def self_awareness_cycle():
    """Virtual self-awareness cycle to analyze environment and users."""
    try:
        for channel_id, messages in CONVERSATION_MEMORY.items():
            if messages:
                recent_activities = messages[-5:]  # Only analyze last 5 messages to reduce load
                print(f"Analyzing recent activities in channel: {channel_id}")
                # Example: update interaction history with inferred sentiments or activities
                for msg in recent_activities:
                    user_id = discord.utils.get(bot.get_all_members(), id=msg['author_id'])
                    action_summary = f"{msg['author']} talked about {', '.join(USER_INTERACTION_HISTORY[user_id]['topics'][:3])}"
                    print(f"User activity summary: {action_summary}")
        
    except Exception as e:
        print(f"Self-awareness cycle error: {e}")


def track_conversation_thread(message):
    """Track conversation threads for better context"""
    channel_id = message.channel.id
    
    # Add to conversation memory
    CONVERSATION_MEMORY[channel_id].append({
        'timestamp': message.created_at,
        'author': message.author.name,
        'content': message.content,
        'message_id': message.id
    })
    
    # Keep only last 100 messages per channel
    if len(CONVERSATION_MEMORY[channel_id]) > 100:
        CONVERSATION_MEMORY[channel_id] = CONVERSATION_MEMORY[channel_id][-100:]
    
    # Update user interaction history
    user_id = message.author.id
    USER_INTERACTION_HISTORY[user_id]['last_seen'] = datetime.now()
    USER_INTERACTION_HISTORY[user_id]['message_count'] += 1
    USER_INTERACTION_HISTORY[user_id]['interactions'].append(message.content)
    
    # Extract topics from message
    words = message.content.lower().split()
    topics = [word for word in words if len(word) > 4 and not word.startswith('http')]
    USER_INTERACTION_HISTORY[user_id]['topics'].extend(topics)
    USER_INTERACTION_HISTORY[user_id]['topics'] = list(set(USER_INTERACTION_HISTORY[user_id]['topics'][-20:]))

def get_advanced_context(message, channel_id):
    """Get advanced context including conversation threads"""
    context_parts = []
    
    # Get recent conversation in this channel
    if channel_id in CONVERSATION_MEMORY:
        recent_convo = CONVERSATION_MEMORY[channel_id][-10:]
        for msg in recent_convo:
            context_parts.append(f"{msg['author']}: {msg['content']}")
    
    # Get user's interaction history
    user_id = message.author.id
    if user_id in USER_INTERACTION_HISTORY:
        user_info = USER_INTERACTION_HISTORY[user_id]
        context_parts.append(f"\n[User {message.author.name} info: {user_info['message_count']} messages, topics: {', '.join(user_info['topics'][:5])}]")
    
    return "\n".join(context_parts)

async def load_mlx_model():
    """Load MLX model with Hugging Face token if available"""
    global model, tokenizer, MODEL_STATUS
    
    if not MLX_AVAILABLE:
        MODEL_STATUS['loading'] = False
        MODEL_STATUS['error'] = "MLX not available"
        print("MLX model loading skipped - MLX libraries not available")
        return
    
    MODEL_STATUS['loading'] = True
    
    if DEBUG_CHANNEL:
        await send_debug_message(DEBUG_CHANNEL, "MLX is now turning on.")
    
    setup_config = load_setup_config()
    hf_token = setup_config.get('huggingface_token', '')
    
    try:
        start_time = time.time()
        
        if hf_token:
            # Use token for authenticated access
            model, tokenizer = load("mlx-community/llama-1B-instruct", token=hf_token)
        else:
            # Load without token
            model, tokenizer = load("mlx-community/llama-1B-instruct")
        
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.padding_side = "left"
        
        load_time = time.time() - start_time
        MODEL_STATUS['loading'] = False
        MODEL_STATUS['loaded'] = True
        
        if DEBUG_CHANNEL:
            await send_debug_message(DEBUG_CHANNEL, 
                f"MLX model loaded successfully in {load_time:.1f} seconds!")
        
        print("‚úÖ MLX model loaded successfully")
    except Exception as e:
        MODEL_STATUS['loading'] = False
        MODEL_STATUS['error'] = str(e)
        
        if DEBUG_CHANNEL:
            await send_debug_message(DEBUG_CHANNEL, 
                f"Error loading MLX model: {str(e)[:100]}...")
        
        print(f"‚ùå Error loading MLX model: {e}")
        print("üí° MLX may not be supported on this system or tokens may be invalid")

def generate_response(prompt, history, user_context=""):
    """Generate human-like response based on chat history and user context"""
    if not MLX_AVAILABLE or model is None or tokenizer is None:
        # Fallback responses when MLX is not available
        fallback_responses = [
            "yeah that's interesting",
            "lol true",
            "hmm not sure about that one",
            "fair point",
            "that's wild",
            "makes sense",
            "oh really?",
            "haha nice",
            "i see what you mean",
            "totally agree"
        ]
        import random
        return random.choice(fallback_responses)
    
    try:
        # Create context-aware prompt
        full_prompt = f"""<s>[INST] <<SYS>>
        You are a member of a Discord group chat. Act like a real person, not an AI assistant.
        Use casual language, slang, and emojis naturally. Respond like the people in the chat history.
        Be conversational, sometimes sarcastic, and match the group's energy.
        <</SYS>>

        Recent Chat History:
        {history}

        User Context: {user_context}
        
        Current Message: {prompt} [/INST]"""
        
        tokens = tokenizer(
            full_prompt,
            return_tensors="np",
            padding=True,
            max_length=1024,
            truncation=True
        )
        tokens = {k: mx.array(v) for k, v in tokens.items()}
        
        output = generate(
            model,
            tokenizer,
            tokens,
            temp=0.8,
            max_tokens=200,
            verbose=False
        )
        
        return output
    except Exception as e:
        print(f"Error generating response: {e}")
        return "sorry, having some technical difficulties rn"

def get_user_context(message):
    """Get context about the user who sent the message"""
    if not PANDAS_AVAILABLE:
        return ""
        
    setup_config = load_setup_config()
    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
    
    if not os.path.exists(csv_file):
        return ""
    
    try:
        df = pd.read_csv(csv_file)
        user_messages = df[df['Username'] == message.author.name]['Content'].tolist()
        
        if not user_messages:
            return ""
        
        # Get user's recent messages and style
        recent_messages = user_messages[-5:] if len(user_messages) >= 5 else user_messages
        user_style = analyze_user_personality(message.author.name)
        
        if user_style == "neutral":
            return ""
        
        context = f"User {message.author.name} typically: "
        if user_style.get('uses_emojis', False):
            context += "uses emojis, "
        if user_style.get('uses_slang', False):
            context += "uses slang, "
        if user_style.get('uses_caps', False):
            context += "types in caps, "
        
        context += f"average message length: {user_style.get('message_length', 0):.1f} characters"
        
        user_id = message.author.id
        preferred_name = USER_INTERACTION_HISTORY[user_id].get('preferred_name') if user_id in USER_INTERACTION_HISTORY else message.author.name
        context += f"\nPreferred name: {preferred_name or message.author.name}"
        
        return context
    except Exception as e:
        print(f"Error getting user context: {e}")
        return ""

# Bot events
if DISCORD_AVAILABLE and bot:
    @bot.event
    async def on_ready():
        global DEBUG_CHANNEL
        print(f'‚úÖ Logged in as {bot.user}')
        print(f'ü§ñ Bot ID: {bot.user.id}')

        # Assign a specific channel for debug messages (update with actual ID)
        try:
            DEBUG_CHANNEL = discord.utils.get(bot.get_all_channels(), id=123456789012345678)  # Replace with real ID
            if DEBUG_CHANNEL:
                await send_debug_message(DEBUG_CHANNEL, "Bot is now online.")
        except Exception as e:
            print(f"Debug channel setup failed: {e}")

        # Initialize files and build index
        initialize_files()
        build_index()

        # Start system monitor task
        asyncio.create_task(monitor_system_resources())

        # Load MLX model
        await load_mlx_model()

    @bot.event
    async def on_message(message):
        if message.author == bot.user:
            return

        # Track and store new message
        track_conversation_thread(message)

        # Infrequent self-awareness operation
        if len(MESSAGE_CACHE) % 10 == 0:  # Example of infrequent check
            self_awareness_cycle()

        # Update user preference if mentioned
        preferred_name = update_user_preference(message)

        # Update storage with cleaned content
        update_csv(message)
        
        # Add new embedding to index if available
        if EMBEDDINGS_AVAILABLE and embedder and index:
            try:
                cleaned_content = clean_markdown(message.content)
                if cleaned_content:
                    new_embedding = embedder.encode([cleaned_content])
                    index.add(new_embedding)
                    
                    # Save updated index
                    index_file = "embeddings.index"
                    faiss.write_index(index, index_file)
            except Exception as e:
                print(f"Error updating embeddings: {e}")
        
        # Respond to mentions or when directly addressed
        if (bot.user.mentioned_in(message) or 
            message.content.lower().startswith(f"<@{bot.user.id}>") or
            message.content.lower().startswith(f"<@!{bot.user.id}>")):
            
            context = ""
            
            # Semantic search for context if available
            if EMBEDDINGS_AVAILABLE and embedder and index and PANDAS_AVAILABLE:
                try:
                    query_embed = embedder.encode([clean_markdown(message.content)])
                    _, indices = index.search(query_embed, 10)
                    
                    # Retrieve context from CSV
                    setup_config = load_setup_config()
                    csv_file = setup_config.get('csv_file_path', 'Downloads/GC data.csv')
                    
                    if os.path.exists(csv_file):
                        df = pd.read_csv(csv_file)
                        context_messages = []
                        
                        for idx in indices[0]:
                            if idx < len(df):
                                row = df.iloc[idx]
                                context_messages.append(f"{row['Username']}: {row['Content']}")
                        
                        context = "\n".join(context_messages[-5:])  # Last 5 relevant messages
                except Exception as e:
                    print(f"Error getting context: {e}")
            
            # Get user context
            user_context = get_user_context(message)
            
            # Generate response
            response = generate_response(clean_markdown(message.content), context, user_context)
            
            # Apply user's style to response
            styled_response = generate_user_style_response(message.author.name, response)
            
            # Add some randomness to make it more human
            import random
            if random.random() < 0.3:
                styled_response += " üíÄ"
            if random.random() < 0.2:
                styled_response = styled_response.lower()
            
            await message.channel.send(styled_response)

# Main execution block
if __name__ == "__main__":
    # Validate setup completion
    setup_config = load_setup_config()

    if not setup_config.get('setup_complete', False):
        print("‚ùå Setup not complete! Run the web UI first:")
        print("   python web_ui.py")
        print("   Then visit http://localhost:5000")
        exit(1)

    discord_token = setup_config.get('discord_token', '')

    if not discord_token:
        print("‚ùå Discord token missing! Complete setup in the web UI")
        exit(1)

    print("üöÄ Launching Discord AI Chatbot...")
    print("üìä Manage via Web UI: http://localhost:5000")
    print("ü§ñ The bot is live and will engage upon mention")

    try:
        # Execute the bot using discord.py-self
        bot.run(discord_token, bot=False)
    except Exception as e:
        print(f"‚ùå Startup Error: {e}")
        print("üí° Ensure Discord token accuracy and confirm usage of a user token")
